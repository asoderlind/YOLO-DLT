{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ccebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def xywh2xyxy(x_center, y_center, w_box, h_box, width, height):\n",
    "    \"\"\"\n",
    "    Convert YOLO format (x_center, y_center, w_box, h_box) to (x1, y1, x2, y2)\n",
    "    \"\"\"\n",
    "    x1 = int((x_center - w_box / 2) * width)\n",
    "    y1 = int((y_center - h_box / 2) * height)\n",
    "    x2 = int((x_center + w_box / 2) * width)\n",
    "    y2 = int((y_center + h_box / 2) * height)\n",
    "\n",
    "    # Clamp the coordinates to be within the image dimensions\n",
    "    x1 = max(0, min(width - 1, x1))\n",
    "    y1 = max(0, min(height - 1, y1))\n",
    "    x2 = max(0, min(width - 1, x2))\n",
    "    y2 = max(0, min(height - 1, y2))\n",
    "\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def xyxy2xywh(x1, y1, x2, y2, width, height):\n",
    "    \"\"\"\n",
    "    Convert (x1, y1, x2, y2) to YOLO format (x_center, y_center, w_box, h_box)\n",
    "    \"\"\"\n",
    "    x_center = (x1 + x2) / 2 / width\n",
    "    y_center = (y1 + y2) / 2 / height\n",
    "    w_box = (x2 - x1) / width\n",
    "    h_box = (y2 - y1) / height\n",
    "\n",
    "    return x_center, y_center, w_box, h_box\n",
    "\n",
    "def filter_occluded_boxes(label_file: str, img_height: int, img_width: int, occlusion_threshold: float =0.5):\n",
    "    # Make annotations array\n",
    "    with open(label_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    num_lines = len(lines)\n",
    "    annotations = np.zeros((num_lines, 5), dtype=np.float32)\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        # Split the line into components\n",
    "        components = line.strip().split()\n",
    "        # Extract the bounding box coordinates\n",
    "        x_center, y_center, w_box, h_box, dist = map(float, components[1:6])\n",
    "\n",
    "        # Convert to (x1, y1, x2, y2) format\n",
    "        x1, y1, x2, y2 = xywh2xyxy(x_center, y_center, w_box, h_box, img_width, img_height)\n",
    "\n",
    "        # Append the bounding box to the list\n",
    "        annotations[i, 0] = x1\n",
    "        annotations[i, 1] = y1\n",
    "        annotations[i, 2] = x2\n",
    "        annotations[i, 3] = y2\n",
    "        annotations[i, 4] = dist\n",
    "\n",
    "\n",
    "    # Sort the annotations by distance, largest to smallest\n",
    "    annotations = annotations[np.argsort(annotations[:, 4])[::-1]]\n",
    "\n",
    "    # Create a mock image with the same height and width as the image\n",
    "    # and a channel for classification\n",
    "    mock_image = np.zeros((img_height, img_width), dtype=np.int8)\n",
    "    mock_image.fill(-1)\n",
    "\n",
    "    total_area_per_annotation = np.zeros(num_lines, dtype=np.float32)\n",
    "    visible_area_per_annotation = np.zeros(num_lines, dtype=np.float32)\n",
    "\n",
    "    # Iterate over each annotation\n",
    "    for i in range(num_lines):\n",
    "        # Get the coordinates of the bounding box\n",
    "        x1, y1, x2, y2 = annotations[i, :4].astype(int)\n",
    "\n",
    "        # Calculate the area of the bounding box\n",
    "        total_area = (x2 - x1) * (y2 - y1)\n",
    "        total_area_per_annotation[i] = total_area\n",
    "\n",
    "        # Add the mask to the mock image\n",
    "        mock_image[y1:y2, x1:x2] = i\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        # Compare the total area with the visible area\n",
    "        visible_area = np.sum(mock_image == i)\n",
    "        visible_area_per_annotation[i] = visible_area\n",
    "\n",
    "    visibility_ratio_per_annotation = visible_area_per_annotation / total_area_per_annotation\n",
    "\n",
    "    # Remove annotations with ratio less than the occlusion threshold\n",
    "    valid_indices = np.where(visibility_ratio_per_annotation >= occlusion_threshold)[0]\n",
    "    annotations = annotations[valid_indices]\n",
    "\n",
    "    # Convert the annotations back to YOLO format\n",
    "    for i in range(len(annotations)):\n",
    "        x1, y1, x2, y2 = annotations[i, :4].astype(int)\n",
    "        x_center, y_center, w_box, h_box = xyxy2xywh(x1, y1, x2, y2, img_width, img_height)\n",
    "        annotations[i, :4] = [x_center, y_center, w_box, h_box]\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8581cea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the bounding boxes on top of a blank image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_label = \"../../yolo-testing/datasets/carla-world06-day/labels/val/vid_86958-Town06-150npc_frame_000065.txt\"\n",
    "img_height, img_width = 600, 800  # Set the desired height and width\n",
    "annotations = filter_occluded_boxes(sample_label, img_height, img_width, occlusion_threshold=0.5)\n",
    "\n",
    "# Create a blank image\n",
    "h, w = 600, 800  # Set the desired height and width\n",
    "image = np.zeros((h,w, 3), dtype=np.uint8)\n",
    "# Set the color for the bounding boxes (BGR format)\n",
    "color = (0, 255, 0)  # Green\n",
    "# Set the thickness of the bounding box lines\n",
    "thickness = 2\n",
    "# Draw the bounding boxes on the image\n",
    "for i in range(annotations.shape[0]):\n",
    "    x1, y1, x2, y2 = xywh2xyxy(*annotations[i, :4], img_width, img_height)\n",
    "    # Draw the rectangle on the image\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "# Display the image with bounding boxes\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")  # Hide the axes\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
